---
title: "Phantom-Words with simultaneous visual presentation - Results"
author: |
    | Ansgar D. Endress
    | City, University of London
bibliography: /Users/endress/ansgar.bib
csl: /Users/endress/csl_files/science.csl
output:
  pdf_document:
    citation_package: natbib
#    includes:
#      in_header: ansgar.sty
    toc: FALSE
    number_sections: true
    keep_tex: true
    fig_caption: true
    highlight: tango    
  html_notebook:
    theme: spacelab      
    number_sections: yes
    toc: yes
    toc_float: yes
    fig_caption: true
    highlight: tango    
  html_document:
    theme: spacelab      
    number_sections: yes
    df_print: paged
    toc: yes
    toc_float: yes
    fig_caption: true
    highlight: tango
keywords: Keywords
abstract: Abstract (to be written)
---

```{r setup, echo = FALSE, include=FALSE}
rm (list=ls())

options(digits = 3,
        knitr.kable.NA = '')
knitr::opts_chunk$set(
    # Run the chunk
    eval = TRUE,
    # Don't include source code
    echo = FALSE, 
    # Print warnings to console rather than the output file
    warning = FALSE,  
    # Stop on errors
    error = FALSE,
    # Print message to console rather than the output file
    message = FALSE,
    # Include chunk output into output
    include = TRUE,
    # Don't reformat R code
    tidy = FALSE,
    # Center images
    fig.align = 'center',
    # Default image width
    out.width = '80%')

# other knits options are here:
# https://yihui.name/knitr/options/
```

```{r set-parameters, echo = FALSE, include=FALSE}

source ('helper/vsl_simultaneous_parameters.R')

#REMOVE.BAD.SUBJ <- FALSE

```

```{r load-libraries, include = FALSE, message = TRUE, warning = TRUE}

if (Sys.info()[["user"]] %in% c("ansgar", "endress")){
    source ("/Users/endress/R.ansgar/ansgarlib/R/tt.R")
    source ("/Users/endress/R.ansgar/ansgarlib/R/null.R")
    #source ("helper_functions.R")
} else {
    # Note that these will probably not be the latest versions
    source("http://endress.org/progs/tt.R")
    source("http://endress.org/progs/null.R")
}


librarian::shelf(
    tidyverse,
    stringr,
    knitr,
    kableExtra,
    ez,
    pwr
# broom,
#broom.mixed,
)

# Don't load simr as it redefines .
if(!librarian::check_installed(simr))
    stop("simr is not installed.")
```

```{r helper-functions}

#' Swap occurrences of two strings in a vector
#'
#' This function replaces all occurrences of the first string with the second string and vice versa in a given string vector.
#'
#' @param string_vector A character vector in which to swap strings.
#' @param string1 The first string to be swapped.
#' @param string2 The second string to be swapped.
#'
#' @return A character vector with the specified strings swapped.
#' @export
#'
#' @examples
#' example_vector <- c("apple", "banana", "apple pie", "banana split")
#' swap_strings(example_vector, "apple", "banana")
swap_strings_in_vector <- function(string_vector = ., string1, string2) {
  placeholder <- "__PLACEHOLDER__"
  
  string_vector %>%
    str_replace_all(fixed(string1), placeholder) %>%
    str_replace_all(fixed(string2), string1) %>%
    str_replace_all(fixed(placeholder), string2)
}


get.power.for.all.effects <- function(model = ., nsim, return.details = FALSE, exclude.intercept = TRUE, ...) {
    
    get.fixed.eff.names <- function(model = ., excude.intercept = TRUE){
        
        all.fixed.effects <- names(fixef(model))
        
        if(exclude.intercept){
            return(all.fixed.effects, "(Intercept)")
        } else {
            return(all.fixed.effects)
        }
        
    }

    # Extract the names of all fixed effects
    fixed.effects <- get.fixed.eff.names(model, exclude.intercept)
    

    power.results <- purrr::map_dfr(fixed.effects,
                                    function(current.effect){
                                        power.results <- simr::powerSim(
                                            fit = model, 
                                            test = simr::fixed(current.effect, "z"), nsim = nsim, ...)
                                        
                                        
                                        simr:::summary.powerSim(power.results) %>% 
                                            dplyr::rename_with(~ str_c("power.", .x)) %>% 
                                            dplyr::mutate(term = current.effect,
                                                          .before = 1)
                                    })
 
    
    if(!return.details){
        power.results <- power.results %>% 
            dplyr::select(power.results, c(term, power.mean))
    }
    

    return(power.results)

}



```


```{r load-data, message = FALSE, include = FALSE}
    
# Age and gender have not been recorded due to experimenter error. 

dat.vsl.simultaneous.fa <- dplyr::bind_rows(
    read.testable.results(
        paste0 (DATA.DIR, "868923_phantoms_fiser_aslin_testable_minds/results"),
        comment.char = "",
        n.subj.info.lines = 2,
        ignore.col.prefixes = IGNORE.COL.PREFIXES,
        stringsAsFactors = FALSE)  %>% 
        mutate (population = "testable"),
    read.testable.results(
        paste0 (DATA.DIR, "777549_phantoms_fiser_aslin_city/results"),
        comment.char = "",
        n.subj.info.lines = 2,
        ignore.col.prefixes = IGNORE.COL.PREFIXES,
        stringsAsFactors = FALSE)  %>% 
        dplyr::mutate(population = "students")
) %>% 
    # these are all rows
    dplyr::filter(my.phase == "test.recognition") %>% 
    # Due to a bug in the experiment, the color.type label was erroneous. We fix it here
    dplyr::mutate(color.type = swap_strings_in_vector(as.character(color.type), "black.on.white", "white.on.black")) %>% 
    dplyr::mutate(dplyr::across(c(filename, color.type, config.id, orientation,
                                  test.type, legal, foil, key), 
                                factor))
    


dat.vsl.simultaneous.fa %>% 
    group_by (population, filename, test.type) %>% 
    summarize (N = n()) %>% 
    group_by (test.type) %>% 
    summarize (N = range (N))

```


# Predictions
The predictions for the current experiment were unclear. On the one hand, it is plausible that observers might encode entire scenes when they are presented simultaneously. If so, they should not accept phantom-words. On the other hand, statistical learning might operate similarly for simultaneous as for sequential presentation. If so, the results with sequential presentations should be replicated, especially because the shapes appear as distinct individual shapes rather than wholes. Further, presenting the shapes   as whole in an object (i.e., in the white on black presentation) might encourage observers to process the combination of shapes as a single hole, leading to the rejection of phantom words.



# Analysis 
## Demographics
```{r vsl-simultaneous-fa-filter-subj}

dat.vsl.simultaneous.fa %>%
    filter (test.type == "w.pw") %>% 
    group_by (population, filename) %>% 
    summarize (correct = mean (correct)) %>% 
    filter (correct <= .5) ->
    dat.vsl.simultaneous.fa.bad.subj
    #find.bad.subj.by.binom.test2 (filename, incorrect, "greater") ->
    


# if (REMOVE.BAD.SUBJ) {
#     dplyr::anti_join(
#         dat.vsl.simultaneous.fa,
#         dat.vsl.simultaneous.fa.bad.subj,
#         by = "filename") -> dat.vsl.simultaneous.fa
#     
# }

# Instead of excluding subjects, we create an extra data frame for the restricted sample

dat.vsl.simultaneous.fa <- dplyr::bind_rows(
    dat.vsl.simultaneous.fa %>% 
        dplyr::mutate(sample.type = "Full sample"),
    
    dplyr::anti_join(
        dat.vsl.simultaneous.fa,
        dat.vsl.simultaneous.fa.bad.subj,
        by = "filename") %>% 
        dplyr::mutate(sample.type = "Restricted sample")
)
    




```

The main experiment recruited participants from testable minds (https://minds.testable.org/). A pilot experiment recruited participants from first year students at City, University of London (UK). In the latter population, other experiments typically need to exclude 30% to 50% of the sample due to insufficient attention. Unfortunately, the present experiment does not offer a clear performance-based criterion to make sure that participants paid attention to the stimuli, as the task might be genuinely difficult. However, given that my main interest lies in the performance on trials involving phantom-words for participants who succeeded in the statistical learning task, it is more conservative to exclude participants whom might not have paid attention to the task, even if this overestimates the statistical learning abilities. 

As a result, I rely on the assumption that earlier statistical learning literature has shown that participants can learn statistical relations *in principle*, and exclude those participants not exceeding an accuracy of 50% on word vs. part-word trials. This criterion led to the removal of `r dat.vsl.simultaneous.fa.bad.subj %>% group_by (population) %>% summarize (N = n ()) %>% pull (N) %>% knitr::combine_words()` participants from the `r dat.vsl.simultaneous.fa.bad.subj %>% group_by (population) %>% summarize (N = n ()) %>% pull (population) %>% knitr::combine_words()` samples, respectively. I present the results from these restricted samples jointly with the results from the full sample. The demographics of the full sample as well as the restricted sample are given in Table \ref{tab:vsl-simultaneous-fa-demographics}. In the student sample, age and gender were not recorded due to experimenter error.

## Analysis strategy

I will analyze the results using two types of analyses. First, I compare the performance in the different trial types to the chance level of 50% using Wilcoxon tests. To compare performance across trial types, I calculate normalized difference scores, that is, $\frac{\text{accuracy}_{\text{trial type 1}} - \text{accuracy}_{\text{trial type 2}}}{\text{accuracy}_{\text{trial type 1}} + \text{accuracy}_{\text{trial type 2}}}$. These difference scores are the compared to the chance level of zero, again using Wilcoxon tests. I also ask whether any of these results is affected by the color polarity type (i.e., black on white vs. white on black).  Following [@Rosenthal1999], I use these focused analyses to target the contrasts of interest, and so that the visualizations match the statistical tests. 

Second, I will confirm these results using a set of generalized linear mixed models with the fixed factor predictors trial type and and color polarity as well as their interaction, and a random intercept for participants. I fitted separate model for each (full vs. restricted) sample and trial contrast (word vs. part-word trials vs. word vs. phantom-word trials and word vs. part-words and phantom-word vs. part-word trials). 

Results from the much larger main sample will be presented in the main text. Results from the student sample will be presented in Supplementary Online Material XXX. 


```{r vsl-simultaneous-fa-average}
dat.vsl.simultaneous.fa %>% 
    dplyr::group_by (population, sample.type, filename, color.type, test.type) %>% 
    dplyr::summarize (
        correct = 100*mean (correct)) -> dat.vsl.simultaneous.fa.m

```

```{r vsl-simultaneous-fa-demographics}


bind_rows(
        dat.vsl.simultaneous.fa %>% 
            get.demographics2(subj = filename, gender = gender, age = age, population, sample.type, color.type, subjectGroup) %>% 
            dplyr::mutate(subjectGroup = as.character(subjectGroup)),
        dat.vsl.simultaneous.fa %>% 
            get.demographics2(subj = filename, gender = gender, age = age, population, sample.type, color.type) %>% 
            dplyr::mutate(subjectGroup = "TOTAL")
    ) %>% 
        dplyr::filter(subjectGroup == "TOTAL") %>% 
        dplyr::select(-subjectGroup) %>% 
        dplyr::mutate(color.type = str_replace_all(color.type, "\\.", " ")) %>% 
        #dplyr::arrange(desc(population), color.type, subjectGroup) %>% 
        dplyr::arrange(sample.type, desc(population), color.type) %>% 
        knitr::kable(
            col.names = c("Population", "Sample type", "Color polarity", "N", "Females", "Males", "Other", "Age", "Age range"),
            caption = "Demographics of the full sample and the restricted sample, where participants were excluded whose accuracy on word vs. part-words trials did not exceed 50 percent. For the student population, age and gender have not been recorded due to experimenter error.",
            booktabs = TRUE) %>% 
        kableExtra::kable_classic_2()

```

```{r vsl-simultaneous-fa-widen}
dat.vsl.simultaneous.fa.m %>% 
    tidyr::pivot_wider(
        id_cols = c(population, sample.type, filename, color.type),
        names_from = test.type,
        values_from = correct,
        names_prefix = "correct.",
        names_sep = ".") %>% 
    dplyr::mutate(#d.absolute.w.pw.ph.pw = 
                   #     (correct.w.pw - correct.phw.pw),
                   # d.absolute.w.pw.w.phw = 
                   #     (correct.w.pw - correct.w.phw),
                   d.relative.w.pw.ph.pw = 
                       (correct.w.pw - correct.phw.pw) / (correct.w.pw + correct.phw.pw),
                   d.relative.w.pw.w.phw = 
                       (correct.w.pw - correct.w.phw) / (correct.w.pw + correct.w.phw)) ->
    dat.vsl.simultaneous.fa.m.wide

# Put all difference scores in single row
dat.vsl.simultaneous.fa.m.wide %>% 
    tidyr::pivot_longer(
        cols = starts_with("d."),
        names_to = "test.type",
        values_to = "d") -> dat.vsl.simultaneous.fa.m.wide.single.d.col


```

## Analysis by accuracy


```{r glmm-verify-effect-of-color-type, eval = FALSE}
# Does color.type play a role? Apparently yes

rbind(
    # Separate models for each test type
    dat.vsl.simultaneous.fa %>% 
        dplyr::group_by(population, sample.type, test.type) %>% 
        dplyr::group_modify(~ anova(glmer(correct ~ color.type + 
                                              (1|filename), 
                                          control=glmerControl(optimizer="bobyqa"),
                                          family="binomial",
                                          data = .x),
                                    glmer(correct ~ 1 + 
                                              (1|filename), 
                                          control=glmerControl(optimizer="bobyqa"),
                                          family="binomial",
                                          data = .x)) %>% 
                                broom::tidy()) %>% 
        dplyr::mutate(model.type = "by test type", .before = 1),
    
    
    # Overall
    dat.vsl.simultaneous.fa %>% 
        dplyr::group_by(population, sample.type) %>% 
        dplyr::group_modify(~ anova(glmer(correct ~ test.type * color.type + 
                                              (1|filename), 
                                          control=glmerControl(optimizer="bobyqa"),
                                          family="binomial",
                                          data = .x),
                                    glmer(correct ~ 1 + 
                                              (1|filename), 
                                          control=glmerControl(optimizer="bobyqa"),
                                          family="binomial",
                                          data = .x)) %>% 
                                broom::tidy()) %>% 
        dplyr::mutate(model.type = "overall", .before = 1)) %>% 
    dplyr::filter(str_detect(term, "color.type")) %>% 
    dplyr::filter(p.value <= .05)
                            
    
    
```



```{r vsl-simultaneous-fa-descriptives-prepare-simple}


dat.vsl.simultaneous.fa.descriptives.simple <- dplyr::bind_rows(
    # Accuracy - descriptives 
    ## Collapsed across polarity types
    dat.vsl.simultaneous.fa.m %>% 
        dplyr::group_by(population, sample.type, test.type) %>% 
        dplyr::summarize(N = n(),
                         M = mean (correct), 
                         SE = se (correct),
                         SD = sd(correct),
                         p.wilcox = wilcox.p(correct, 50),
                         power = pwr::pwr.t.test(d = (M - 50)/SD, n = N, sig.level = .05, power = NULL,  type  = "one.sample", alternative = "two.sided")$power,
        #ss.80  = pwr::pwr.t.test(d = (M - 50)/SD,  sig.level = .05, power = .8,  type  = "one.sample", alternative = "two.sided")$n,
                         .groups = "drop") %>% 
        dplyr::select(-SD) %>% 
        dplyr::mutate(r.wilcox = get.r.from.wilcox.p(N = N, p = p.wilcox)) %>% 
        dplyr::mutate(color.type = "Zcombined", .after = "sample.type"),
    
    ## Separately by polarity type
    dat.vsl.simultaneous.fa.m %>% 
        dplyr::group_by(population, sample.type, color.type, test.type) %>% 
        dplyr::summarize(N = n(),
                         M = mean(correct), 
                         SE = se(correct),
                         SD = sd(correct),
                         p.wilcox = wilcox.p(correct, 50),
                         power = pwr::pwr.t.test(d = (M - 50)/SD, n = N, sig.level = .05, power = NULL,  type  = "one.sample", alternative = "two.sided")$power,
        #ss.80  = pwr::pwr.t.test(d = (M - 50)/SD,  sig.level = .05, power = .8,  type  = "one.sample", alternative = "two.sided")$n,                         
                         .groups = "drop") %>% 
        dplyr::mutate(r.wilcox = get.r.from.wilcox.p(N = N, p = p.wilcox)) %>% 
        dplyr::select(-SD))


```

```{r vsl-simultaneous-fa-descriptives-prepare-diff-scores}

dat.vsl.simultaneous.fa.descriptives.diff.scores <- dplyr::bind_rows(
    # Difference scores - descriptives
    ## Collapsed across polarity types
    dat.vsl.simultaneous.fa.m.wide.single.d.col %>% 
        dplyr::select (population, sample.type, filename, color.type, test.type, d) %>% 
        group_by(population, sample.type, test.type) %>% 
        summarize(N = n(),
                  M = mean (d), 
                  SE = se (d),
                  SD = sd(d),
                  p.wilcox = wilcox.p(d, 0),
                  power = pwr::pwr.t.test(d = M/SD, n = N, sig.level = .05, power = NULL,  type  = "one.sample", alternative = "two.sided")$power,
        #ss.80  = pwr::pwr.t.test(d = M/SD,  sig.level = .05, power = .8,  type  = "one.sample", alternative = "two.sided")$n,                  
                  .groups = "drop") %>% 
        dplyr::mutate(r.wilcox = get.r.from.wilcox.p(N = N, p = p.wilcox)) %>% 
        dplyr::mutate(color.type = "Zcombined", .after = "sample.type"),
    
    ## Separately by polarity type
    dat.vsl.simultaneous.fa.m.wide.single.d.col %>% 
        dplyr::select (population, sample.type, filename, color.type, test.type, d) %>% 
        group_by(population, sample.type, color.type, test.type) %>% 
        summarize(N = n(),
                  M = mean (d), 
                  SE = se (d),
                  SD = sd(d),
                  p.wilcox = wilcox.p(d, 0),
                  power = pwr::pwr.t.test(d = M/SD, n = N, sig.level = .05, power = NULL,  type  = "one.sample", alternative = "two.sided")$power,
                  #ss.80  = pwr::pwr.t.test(d = M/SD,  sig.level = .05, power = .8,  type  = "one.sample", alternative = "two.sided")$n,                  
                  .groups = "drop") %>% 
        dplyr::mutate(r.wilcox = get.r.from.wilcox.p(N = N, p = p.wilcox))) %>%     
        dplyr::select(-SD)
```

```{r vsl-simultaneous-fa-descriptives-prepare-effecs-polarity-type}

dat.vsl.simultaneous.fa.descriptives.effect.polarity <- dplyr::bind_rows(
    
    # Accuracy - effect of color.type
    dplyr::left_join(
        # Calculate descriptives
        dat.vsl.simultaneous.fa.m %>% 
            dplyr::group_by(population, sample.type, test.type) %>% 
            rstatix::wilcox_test(correct ~ color.type, paired = FALSE) %>% 
            dplyr::rename(p.wilcox = p) %>% 
            dplyr::mutate(r.wilcox = get.r.from.wilcox.p(N = n1 + n2, p = p.wilcox)) %>% 
            dplyr::select(population, sample.type, test.type, p.wilcox, r.wilcox) %>% 
            dplyr::mutate(color.type = "zEffect of color polarity"),
        
        # Calculate power
        dat.vsl.simultaneous.fa.descriptives.simple %>% 
            dplyr::filter(color.type != "Zcombined") %>% 
            dplyr::mutate(SD = SE * sqrt(N-1)) %>% 
            dplyr::select(population, sample.type, test.type, color.type, N, M, SD) %>% 
            tidyr::pivot_wider(id_cols = c(population, sample.type, test.type),
                               names_from = color.type,
                               values_from = c(N, M, SD)) %>% 
            dplyr::mutate(sd.pooled = sqrt(((N_black.on.white - 1) * SD_black.on.white^2 + 
                                                (N_white.on.black - 1) * SD_white.on.black^2) / 
                                               (N_black.on.white + N_white.on.black - 2)),
                          eff.size = abs(M_white.on.black - M_black.on.white)/ sd.pooled,
                          power = pwr::pwr.t2n.test(n1 = N_white.on.black, n2 = N_black.on.white, d = eff.size, sig.level = .05, power = NULL,  alternative = "two.sided")$power) %>% 
                          #ss.80  = purrr::map_dbl(eff.size, 
                                                  #~ 2 * pwr::pwr.t.test(d = .x, sig.level = .05, power = .8,  type  = "two.sample", alternative = "two.sided")$n)) %>% 
            dplyr::select(population, sample.type, test.type, power),
        
        by = c("population", "sample.type", "test.type")),
    
    
    
    # Difference scores - effect of color type
    dplyr::left_join(
        # Calculate descriptives
        dat.vsl.simultaneous.fa.m.wide.single.d.col %>% 
            dplyr::group_by(population, sample.type, test.type) %>% 
            rstatix::wilcox_test(d ~ color.type, paired = FALSE) %>% 
            dplyr::rename(p.wilcox = p) %>% 
            dplyr::mutate(r.wilcox = get.r.from.wilcox.p(N = n1 + n2, p = p.wilcox)) %>% 
            dplyr::select(population, sample.type, test.type, p.wilcox, r.wilcox) %>% 
            dplyr::mutate(color.type = "zEffect of color polarity"),
    
    
    # Calculate power
        dat.vsl.simultaneous.fa.descriptives.diff.scores %>% 
            dplyr::filter(color.type != "Zcombined") %>% 
            dplyr::mutate(SD = SE * sqrt(N-1)) %>% 
            dplyr::select(population, sample.type, test.type, color.type, N, M, SD) %>% 
            tidyr::pivot_wider(id_cols = c(population, sample.type, test.type),
                               names_from = color.type,
                               values_from = c(N, M, SD)) %>% 
            dplyr::mutate(sd.pooled = sqrt(((N_black.on.white - 1) * SD_black.on.white^2 + 
                                                (N_white.on.black - 1) * SD_white.on.black^2) / 
                                               (N_black.on.white + N_white.on.black - 2)),
                          eff.size = abs(M_white.on.black - M_black.on.white)/ sd.pooled,
                          power = pwr::pwr.t2n.test(n1 = N_white.on.black, n2 = N_black.on.white, d = eff.size, sig.level = .05, power = NULL,  alternative = "two.sided")$power) %>% 
                          #ss.80  = purrr::map_dbl(eff.size, 
                                                  #~ 2 * pwr::pwr.t.test(d = .x, sig.level = .05, power = .8,  type  = "two.sample", alternative = "two.sided")$n)) %>% 
            dplyr::select(population, sample.type, test.type, power),
        
        by = c("population", "sample.type", "test.type")))




```    

```{r vsl-simultaneous-fa-descriptives-prepare-combine-and-correct}

l.vsl.simultaneous.fa.descriptives <- dplyr::bind_rows(
    dat.vsl.simultaneous.fa.descriptives.simple,
    dat.vsl.simultaneous.fa.descriptives.diff.scores,
    dat.vsl.simultaneous.fa.descriptives.effect.polarity) %>% 
    
    # Correct for repeated measures
    dplyr::group_by(population, sample.type) %>% 
    dplyr::mutate(p.hb = p.adjust(p.wilcox, method = "holm"),
                  .after = "p.wilcox") %>% 
    dplyr::ungroup() %>% 
    
    dplyr::arrange(desc(population), sample.type, color.type, desc(test.type)) %>%
    tidyr::unite(sample.type.color.type, sample.type, color.type, sep = " - ") %>%
    dplyr::mutate(sample.type.color.type.n = ifelse(is.na(N),
                                                    sample.type.color.type,
                                                    str_c(sample.type.color.type, " (N = ", N, ")")), .keep = "unused") %>% 
    dplyr::relocate(r.wilcox, .before = "power") %>% 
    split(f = as.factor(.$population))

```

```{r vsl-simultaneous-fa-descriptives-print-testable}
l.vsl.simultaneous.fa.descriptives$testable %>% 
    dplyr::select(-population) %>% 
    kable.packed("sample.type.color.type.n",
                 caption = "Descriptives of accuracy scores and difference scores for the main sample. The restricted sample consists of participants whose performance exceeded 50\\% on word vs. part-word trials. The p value reflects a Wilcoxon test against the chance levels of 50 percent and of zero for accuracies and difference scores, respectively. The effect of color polarity represents a Wilcoxon test comparing all of these dependent variables as a function of color polarity. The p value was corrected for repeated testing using the Holm-Bonferroni method, separately for each (full or restricted) sample (pHB). In the restricted sample, comparisons of the word vs. part-word contrast against chance are not meaningful as participants were selected based on their performance in this comparison.",
                 #col.names = c("", "*M*", "*SE*", "*p.wilcoxon*"),
                 booktabs = TRUE,
                 longtable = TRUE
                 #escape = FALSE
                 ) %>%
    kableExtra::kable_styling(latex_options = c("striped",
                                                "scale_down",
                                                "hold_position",
                                                "repeat_header")) %>%
    kableExtra::kable_classic_2()


```



```{r vsl-simultaneous-fa-plot-accuracy-prepare-by-polarity}

p.vsl.simultaneous.fa.accuracy.by.polarity <- dat.vsl.simultaneous.fa.m %>%
    dplyr::mutate (test.type = factor(test.type, 
                                      levels = c("w.pw", "phw.pw", "w.phw"))) %>% 
    dplyr::mutate(population = factor(population, levels = c("testable", "students"))) %>% 
    dplyr::group_by(population) %>% 
    dplyr::group_modify(~ {
        p <- ggplot(.x, aes(x = test.type, y = correct)) %>% 
            violin_plot_template(yintercept = 50) +
            scale_x_discrete("Test type",
                             labels = c("Word vs. part-word", 
                                        "Phantom-word vs .part-word", 
                                        "Word vs. Phantom-Word") %>% 
                                 str_wrap(width = 15)) +
            theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=.5)) +
            scale_y_continuous("% Correct") + 
            facet_grid(sample.type ~ color.type,
                       labeller = labeller (color.type = ~ str_replace_all(.x, "\\.", " ") %>% 
                                                str_to_sentence)) 
        
        # Return the plot as a one-row tibble
        tibble(plot = list(p))
    },
    .keep = TRUE) %>% 
    dplyr::ungroup() %>% 
    tibble::deframe()
```

```{r vsl-simultaneous-fa-plot-accuracy-prepare-polarity-collapsed}

p.vsl.simultaneous.fa.accuracy.polarity.collapsed <- dat.vsl.simultaneous.fa.m %>%
    dplyr::mutate (test.type = factor(test.type, 
                                      levels = c("w.pw", "phw.pw", "w.phw"))) %>% 
    dplyr::mutate(population = factor(population, levels = c("testable", "students"))) %>% 
    dplyr::group_by(population) %>% 
    dplyr::group_modify(~ {
        p <- ggplot(.x, aes(x = test.type, y = correct)) %>% 
            violin_plot_template(yintercept = 50, dotsize = .5) +
            scale_x_discrete("Test type",
                             labels = c("Word vs. part-word", 
                                        "Phantom-word vs .part-word", 
                                        "Word vs. Phantom-Word") %>% 
                                 str_wrap(width = 15)) +
            theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=.5)) +
            scale_y_continuous("% Correct") + 
            facet_grid(sample.type ~ .,
                       labeller = labeller (color.type = ~ str_replace_all(.x, "\\.", " ") %>% 
                                                str_to_sentence))
        
        # Return the plot as a one-row tibble
        tibble(plot = list(p))
    },
    .keep = TRUE) %>% 
    dplyr::ungroup() %>% 
    tibble::deframe()
```



```{r vsl-simultaneous-fa-plot-difference-scores-prepare-by-polarity}

p.vsl.simultaneous.fa.diff.scores.by.polarity <- dat.vsl.simultaneous.fa.m.wide.single.d.col %>% 
        dplyr::filter(str_detect(test.type, "relative")) %>% 
        dplyr::mutate(population = factor(population, levels = c("testable", "students"))) %>% 
        dplyr::mutate(test.type = dplyr::case_when(
            test.type == "d.relative.w.pw.ph.pw" ~ "$\\frac{W//PW - PhW//PW}{W//PW + PhW//PW}$",
            test.type == "d.relative.w.pw.w.phw" ~ "$\\frac{W//PW - W//PhW}{W//PW + W//PhW}$",
            TRUE ~ NA_character_)) %>% 
    dplyr::group_by(population) %>% 
    dplyr::group_modify(~ {
        p <-ggplot(.x, aes(x = test.type, y = d)) %>% 
            violin_plot_template(yintercept = 0) +
            scale_x_discrete(labels = function(x) sapply(x, function(x) latex2exp::TeX(x))) +
            theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=.5)) +
            scale_y_continuous("Relative difference score") + 
            facet_grid (sample.type ~ color.type,
                        labeller = labeller(color.type = ~ str_replace_all(.x, "\\.", " ") %>% 
                                                str_to_sentence)) 
        
                # Return the plot as a one-row tibble
        tibble(plot = list(p))
    },
    .keep = TRUE) %>% 
    dplyr::ungroup() %>% 
    tibble::deframe()
```

```{r vsl-simultaneous-fa-plot-difference-scores-prepare-polarity-collapsed}

p.vsl.simultaneous.fa.diff.scores.polarity.collapsed <- dat.vsl.simultaneous.fa.m.wide.single.d.col %>% 
        dplyr::filter(str_detect(test.type, "relative")) %>% 
        dplyr::mutate(population = factor(population, levels = c("testable", "students"))) %>% 
        dplyr::mutate(test.type = dplyr::case_when(
            test.type == "d.relative.w.pw.ph.pw" ~ "$\\frac{W//PW - PhW//PW}{W//PW + PhW//PW}$",
            test.type == "d.relative.w.pw.w.phw" ~ "$\\frac{W//PW - W//PhW}{W//PW + W//PhW}$",
            TRUE ~ NA_character_)) %>% 
    dplyr::group_by(population) %>% 
    dplyr::group_modify(~ {
        p <-ggplot(.x, aes(x = test.type, y = d)) %>% 
            violin_plot_template(yintercept = 0, dotsize = .5) +
            scale_x_discrete(labels = function(x) sapply(x, function(x) latex2exp::TeX(x))) +
            theme(axis.text.x = element_text(angle=45, vjust=.5, hjust=.5)) +
            scale_y_continuous("Relative difference score") + 
            facet_grid (sample.type ~ .,
                        labeller = labeller(color.type = ~ str_replace_all(.x, "\\.", " ") %>%
                                                str_to_sentence)) 
        
                # Return the plot as a one-row tibble
        tibble(plot = list(p))
    },
    .keep = TRUE) %>% 
    dplyr::ungroup() %>% 
    tibble::deframe()


```



```{r vsl-simultaneous-fa-plot-accuracy-diff-scores-plot-polarity-collapsed-testable, fig.cap="(a) Accuracy in the different trial types (words vs. part-words, phantom-words vs. part-words, and words vs. phantom-words), (b)  Relative difference scores for contrasts between different trial types (word vs. part-word trials vs. phantom-word vs. part-word trials, and word vs. part-word trials vs. word vs. phantom-word trials). Both panels show the data for the full main sample (top) or after exclusion of participants whose performance did not exceed 50\\% in the word vs. part-word trials (bottom), collapsed across polarity contrasts (black shapes on a white background vs. white shapes on a black background). The dots, error bars and violin represent the sample averages, 95\\% bootstrap confidence intervals and the distribution of the average accuracy for individual participants, respectively. Empty circles represent individual participants.", fig.width=11, fig.height=11}


ggpubr::ggarrange(
    p.vsl.simultaneous.fa.accuracy.polarity.collapsed$testable + 
        theme(
            axis.title = element_text(size = 18),        # Axis labels
            axis.text = element_text(size = 16),         # Axis annotations (tick labels)
            strip.text = element_text(size = 20)         # Facet labels
        ),
    p.vsl.simultaneous.fa.diff.scores.polarity.collapsed$testable + 
                theme(
            axis.title = element_text(size = 18),        # Axis labels
            axis.text = element_text(size = 16),         # Axis annotations (tick labels)
            strip.text = element_text(size = 20)         # Facet labels
        ),
    nrow = 1, ncol = 2,
    #common.legend = TRUE, legend="bottom", 
    #legend.grob = plot.circle.combined.within.recency.legend,
    label.y = .075,
    labels = "auto")



```


As shown in Table \ref{tab:vsl-simultaneous-fa-descriptives-print-testable} and Figure \ref{fig:vsl-simultaneous-fa-plot-accuracy-diff-scores-plot-polarity-collapsed-testable}a, participants from the main sample preferred both words and phantom-words to part-words.^[The above chance performance in the restricted sample is meaningless, since only those participants were included who exceeded 50% on the word vs. part-word test.] In contrast, they had no preference for words over phantom-words. Similar results were obtained for both color polarity types, with no discernible effect of color polarity type. This results held in both the full sample and the restricted sample. (Individual results for the different polarity types are given in Figure \ref{fig:vsl-simultaneous-fa-plot-accuracy-plot-by-polarity-testable}.)

To compare performance in the different trial types, I calculated the difference scores mentioned above. As shown in Table  \ref{tab:vsl-simultaneous-fa-descriptives-print-testable} and Figure \ref{fig:vsl-simultaneous-fa-plot-accuracy-diff-scores-plot-polarity-collapsed-testable}b, participants from the testable sample performed much better on word vs. part-word trials than on word vs. phantom-word trials, irrespective of the color polarity type. This suggests that participants find discriminations based on TPs much easier than discriminations based on frequency of occurrence, which is problematic if statistical learning leads to memory for units. (Individual results for the different polarity types are given in Figure \ref{fig:vsl-simultaneous-fa-plot-difference-scores-plot-testable}.)

However, at least in the restricted sample, performance was also somewhat better for word vs. part-word trials than for phantom-word vs. part-word trials, suggesting that we cannot rule out that participants might also have some ability to track frequencies of occurrence. However, the corresponding difference score was much smaller than that comparing words vs. part-word and word vs. phantom-word trials, and was not significant in the full sample.

As shown in Supplementary Online Material XXX, the results were similar for the student samnple, except that the data was noisier.



```{r vsl-simultaneous-fa-plot-glmer-correct-calculate-old, eval = FALSE}

l.vsl.simultaneous.fa.glmer <- dplyr::bind_rows(
    # W vs. PW vs. W vs. PhW
    dat.vsl.simultaneous.fa %>% 
        #dplyr::filter(population == "testable") %>% 
        dplyr::filter((test.type == "w.pw") | 
                          (test.type == "w.phw")) %>% 
        dplyr::mutate(comparison.type = paste0(unique(test.type), collapse = " vs. ")) %>% 
        dplyr::group_by(population, sample.type, comparison.type) %>% 
        dplyr::group_modify(~ glmer(correct ~ test.type + color.type + 
                                        (1 | filename), 
                                    control=glmerControl(optimizer="bobyqa"),
                                    family="binomial",
                                    data = .x) %>% 
                                extract.results.from.binary.model) %>% 
        dplyr::ungroup(),
    
    # W vs. PW vs. PhW vs. PW
    dat.vsl.simultaneous.fa %>% 
        #dplyr::filter(population == "testable") %>% 
        dplyr::filter((test.type == "w.pw") | 
                          (test.type == "phw.pw")) %>% 
        dplyr::mutate(comparison.type = paste0(unique(test.type), collapse = " vs. ")) %>% 
        dplyr::group_by(population, sample.type, comparison.type) %>% 
        dplyr::group_modify(~ glmer(correct ~ test.type * color.type + 
                                        (1 | filename), 
                                    control=glmerControl(optimizer="bobyqa"),
                                    family="binomial",
                                    data = .x) %>% 
                                extract.results.from.binary.model)) %>% 
    dplyr::select (-c("t_log", "p_log")) %>% 
    #filter (p <= .1)  %>% 
    dplyr::filter (!str_detect (term, "Intercept")) %>% 
    dplyr::arrange(desc(population), sample.type, desc(comparison.type)) %>% 
    tidyr::unite(pack.col, sample.type, comparison.type, sep = " - ") %>% 
    split(f = as.factor(.$population))
```


```{r vsl-simultaneous-fa-plot-glmer-correct-calculate}

dat.vsl.simultaneous.fa.glmer <- dplyr::bind_rows(
    # W vs. PW vs. W vs. PhW
    dat.vsl.simultaneous.fa %>% 
        #dplyr::filter(population == "testable") %>% 
        dplyr::filter((test.type == "w.pw") | 
                          (test.type == "w.phw")) %>% 
        dplyr::mutate(comparison.type = paste0(unique(test.type), collapse = " vs. ")) %>% 
        dplyr::group_by(population, sample.type, comparison.type) %>% 
        dplyr::group_modify(~  tibble( model = 
                                           glmer(correct ~ test.type * color.type + 
                                                     (1 | filename), 
                                                 control=glmerControl(optimizer="bobyqa"),
                                                 family="binomial",
                                                 data = .x) %>% 
                                           list)) %>% 
        dplyr::ungroup(),
    
    # W vs. PW vs. PhW vs. PW
    dat.vsl.simultaneous.fa %>% 
        #dplyr::filter(population == "testable") %>% 
        dplyr::filter((test.type == "w.pw") | 
                          (test.type == "phw.pw")) %>% 
        dplyr::mutate(comparison.type = paste0(unique(test.type), collapse = " vs. ")) %>% 
        dplyr::group_by(population, sample.type, comparison.type) %>% 
        dplyr::group_modify(~ tibble(model = 
                                         glmer(correct ~ test.type * color.type + 
                                                   (1 | filename), 
                                               control=glmerControl(optimizer="bobyqa"),
                                               family="binomial",
                                               data = .x) %>% 
                                         list)) %>% 
        dplyr::ungroup()) 




```


```{r vsl-simultaneous-fa-plot-glmer-correct-extract-results-and-add-power, include = FALSE, message = FALSE}





l.vsl.simultaneous.fa.glmer <- dplyr::left_join(
    dat.vsl.simultaneous.fa.glmer %>% 
        dplyr::mutate(model.results = purrr::map(model, 
                                                 extract.results.from.binary.model)) %>% 
        tidyr::unnest(model.results) %>% 
        dplyr::select(-model),
    
    dat.vsl.simultaneous.fa.glmer %>% 
        dplyr::mutate(power.results = purrr::map(model, 
                                                 ~ get.power.for.all.effects(
                                                     model = .x, 
                                                     nsim = 1000, 
                                                     return.details = TRUE,
                                                     exclude.intercept = FALSE)
        )) %>% 
        tidyr::unnest(power.results) %>% 
        dplyr::select(-model),
    
    by = c("population", "sample.type", "comparison.type", "term")) %>% 
    dplyr::select(-c(t_log, p_log)) %>% 
    dplyr::rename(power = power.mean) %>% 
#    dplyr::mutate(p.successfull.sims = power.successes/power.trials,
#                  .after = "power") %>% 
    dplyr::select(-dplyr::starts_with(fixed("power."))) %>%
    #filter (p <= .1)  %>%
    dplyr::filter (!str_detect (term, "Intercept")) %>%
    dplyr::arrange(desc(population), sample.type, desc(comparison.type)) %>%
    tidyr::unite(pack.col, sample.type, comparison.type, sep = " - ") %>%
    split(f = as.factor(.$population))


```





```{r vsl-simultaneous-fa-plot-glmer-correct-print-testable}

l.vsl.simultaneous.fa.glmer$testable %>% 
    dplyr::select(-population) %>% 
    kable.packed ("pack.col",
                  caption = "Results of generalized linear mixed models for trial-by-trial responses, for the main sample. Results are reported for the full sample as well as the restricted sample, where participants were excluded if their performance did not exceed 50\\% on the word vs. part-word trials.",
                  col.names = str_remove(names (.)[-1], "_.*$"), 
                  booktabs = TRUE) %>% 
    kableExtra::add_header_above(c(" " = 1, "Log-odds" = 3, "Odd ratios" = 3, " " = 3)) %>% 
    kableExtra::kable_styling(latex_options =
                                  c("scale_down",
                                    "hold_position")) %>% 
    #"striped")) %>% 
    kable_classic_2()

```

I confirmed these results using the generalized linear mixed models mentioned above. As shown in Table \ref{tab:vsl-simultaneous-fa-plot-glmer-correct-print-testable}, the models showed that performance on word vs. part-word trials was significantly better than for word vs. phantom-word trials. They also showed that performance on word vs. part-word trials was significantly better than on phantom-word vs. part-word trials, though this predictor was significant only in the restricted sample and was only marginal in the full sample. Further, the odds ratio associated with the former contrast was almost twice as large as that from the latter contrast.

There were no main effects or interactions with polarity type. The results for the student sample were generally similar. 



# Discussion

`r clearpage()`

# Appendix 1: Results split by polarity type

```{r vsl-simultaneous-fa-plot-accuracy-plot-by-polarity-testable, fig.cap="Accuracy in the different trial types (words vs. part-words, phantom-words vs. part-words, and words vs. phantom-words), for the full main sample (top) or after exclusion of participants whose performance did not exceed 50\\% in the word vs. part-word trials (bottom), for black shapes on a white background (left) and white shapes on a black background (right). The dots, error bars and violin represent the sample averages, 95\\% bootstrap confidence intervals and the distribution of the average accuracy for individual participants, respectively. Empty circles represent individual participants."}

p.vsl.simultaneous.fa.accuracy.by.polarity$testable

```




```{r vsl-simultaneous-fa-plot-difference-scores-plot-testable, fig.cap="Relative difference scores for contrasts between different trial types (word vs. part-word trials vs. phantom-word vs. part-word trials, and word vs. part-word trials vs. word vs. phantom-word trials), for the full main sample or after exclusion of participants whose performance did not exceed 50\\% in the word vs. part-word trials. The dots, error bars and violin represent the sample averages, 95\\% bootstrap confidence intervals and the distribution of the difference scores for individual participants, respectively. Empty circles represent individual participants."}
    
p.vsl.simultaneous.fa.diff.scores.by.polarity$testable
    
```



`r clearpage()`

# Appendix 2: Results with the student sample

```{r vsl-simultaneous-fa-descriptives-print-city}    
l.vsl.simultaneous.fa.descriptives$students %>% 
    dplyr::select(-population) %>% 
    kable.packed("sample.type.color.type.n",
                 caption = "Descriptives of accuracy scores and difference scores for the student sample. The restricted sample consists of participants whose performance exceeded 50\\% on word vs. part-word trials. The p value reflects a Wilcoxon test against the chance levels of 50 percent and of zero for accuracies and difference scores, respectively. The effect of color polarity represents a Wilcoxon test comparing all of these dependent variables as a function of color polarity. The p value was corrected for repeated testing using the Holm-Bonferroni method, separately for each (full or restricted) sample (pHB). In the restricted sample, comparisons of the word vs. part-word contrast against chance are not meaningful as participants were selected based on their performance in this comparison.",
                 #col.names = c("", "*M*", "*SE*", "*p.wilcoxon*"),
                 booktabs = TRUE) %>%
    kableExtra::kable_classic_2()



```

```{r vsl-simultaneous-fa-plot-accuracy-diff-scores-plot-polarity-collapsed-city, fig.cap="(a) Accuracy in the different trial types (words vs. part-words, phantom-words vs. part-words, and words vs. phantom-words), (b)  Relative difference scores for contrasts between different trial types (word vs. part-word trials vs. phantom-word vs. part-word trials, and word vs. part-word trials vs. word vs. phantom-word trials). Both panels show the data for the full student sample (top) or after exclusion of participants whose performance did not exceed 50\\% in the word vs. part-word trials (bottom), collapsed across polarity contrasts (black shapes on a white background vs. white shapes on a black background). The dots, error bars and violin represent the sample averages, 95\\% bootstrap confidence intervals and the distribution of the average accuracy for individual participants, respectively. Empty circles represent individual participants.", fig.width=11, fig.height=11}


ggpubr::ggarrange(
    p.vsl.simultaneous.fa.accuracy.polarity.collapsed$students + 
                theme(
            axis.title = element_text(size = 18),        # Axis labels
            axis.text = element_text(size = 16),         # Axis annotations (tick labels)
            strip.text = element_text(size = 20)         # Facet labels
        ),
    p.vsl.simultaneous.fa.diff.scores.polarity.collapsed$students + 
                theme(
            axis.title = element_text(size = 18),        # Axis labels
            axis.text = element_text(size = 16),         # Axis annotations (tick labels)
            strip.text = element_text(size = 20)         # Facet labels
        ),
    nrow = 1, ncol = 2,
    #common.legend = TRUE, legend="bottom", 
    #legend.grob = plot.circle.combined.within.recency.legend,
    label.y = .075,
    labels = "auto")



```




```{r vsl-simultaneous-fa-plot-accuracy-plot-by-polarity-city, fig.cap="Accuracy in the different trial types (words vs. part-words, phantom-words vs. part-words, and words vs. phantom-words), for the full student sample (top) or after exclusion of participants whose performance did not exceed 50\\% in the word vs. part-word trials (bottom), for black shapes on a white background (left) and white shapes on a black background (right). The dots, error bars and violin represent the sample averages, 95\\% bootstrap confidence intervals and the distribution of the average accuracy for individual participants, respectively. Empty circles represent individual participants."}

p.vsl.simultaneous.fa.accuracy.by.polarity$students


```

```{r vsl-simultaneous-fa-plot-difference-scores-plot-by-polarity-city, fig.cap="Relative difference scores for contrasts between different trial types (word vs. part-word trials vs. phantom-word vs. part-word trials, and word vs. part-word trials vs. word vs. phantom-word trials), for the full student sample or after exclusion of participants whose performance did not exceed 50\\% in the word vs. part-word trials. The dots, error bars and violin represent the sample averages, 95\\% bootstrap confidence intervals and the distribution of the difference scores for individual participants, respectively. Empty circles represent individual participants."}
    
p.vsl.simultaneous.fa.diff.scores.by.polarity$students
    
```


The results for the student sample depended somewhat on whether the full sample or the restricted sample were analyzed, and on whether a correction for repeated testing was applied. This is presumably due to a combination of the limited sample size, and the usually high proportion of participants paying no attention to the stimuli.  

The results for raw accuracy scores are given in Table \ref{tab:vsl-simultaneous-fa-descriptives-print-city} and Figure \ref{fig:vsl-simultaneous-fa-plot-accuracy-diff-scores-plot-polarity-collapsed-city}a. (Individual results for the different polarity types are given in Figure \ref{fig:vsl-simultaneous-fa-plot-accuracy-plot-by-polarity-city}.)

While participants in the restricted sample preferred words over part-words (unsurprisingly, given that only those participants were included who exceeded 50% on the word vs. part-word test), this preference was only significant in the full sample when the Holm-Bonferroni correction was not applied. In the restricted sample, participants also preferred phantom-words to part-words, though this preference survived the Holm-Bonferroni correction only when white shapes were presented on a black background. In the full sample, this preference was not significant. They had no preference for words over phantom-words. There was no discernible effect of color polarity type. 

To compare performance in the different trial types, I calculated the difference scores mentioned above. As shown in Table  \ref{tab:vsl-simultaneous-fa-descriptives-print-city} and Figure \ref{fig:vsl-simultaneous-fa-plot-accuracy-diff-scores-plot-polarity-collapsed-city}b, participants from the student sample performed much better on word vs. part-word trials than on word vs. phantom-word trials. While this effect was generally significant before applying the Holm-Bonferroni correction, it did not survive this correction for all polarity types. Be that as it may, these results suggest that participants find discriminations based on TPs much easier than discriminations based on frequency of occurrence, which is problematic if statistical learning leads to memory for units. (Individual results for the different polarity types are given in \ref{fig:vsl-simultaneous-fa-plot-difference-scores-plot-city}.)

However, at least in the restricted sample, performance was also somewhat better for word vs. part-word trials than for phantom-word vs. part-word trials, suggesting that we cannot rule out that participants might also have some ability to track frequencies of occurrence. However, the corresponding difference score was much smaller than that comparing words vs. part-word and word vs. phantom-word trials, and was not significant in the full sample.


```{r vsl-simultaneous-fa-plot-glmer-correct-print-city}
l.vsl.simultaneous.fa.glmer$student %>% 
    dplyr::select(-population) %>% 
    kable.packed ("pack.col",
                  caption = "Results of generalized linear mixed models for trial-by-trial responses, for the student sample. Results are reported for the full sample as well as the restricted sample, where participants were excluded if their performance did not exceed 50\\% on the word vs. part-word trials.",
                  col.names = str_remove(names (.)[-1], "_.*$"), 
                  booktabs = TRUE) %>% 
    kableExtra::add_header_above(c(" " = 1, "Log-odds" = 3, "Odd ratios" = 3, " " = 3)) %>% 
    kableExtra::kable_styling(latex_options =
                                  c("scale_down",
                                    "hold_position")) %>% 
    #"striped")) %>% 
    kable_classic_2()

```

I confirmed these results using the generalized linear mixed models above. As shown in Table \ref{tab:vsl-simultaneous-fa-plot-glmer-correct-print-city}, the models showed that performance on word vs. part-word trials was significantly better than for word vs. phantom-word trials. They also showed that performance on word vs. part-word trials was significantly better than on phantom-word vs. part-word trials, though this predictor was significant only in the restricted sample but not for the full sample. In the model comparing word vs. phantom-word trials and word vs. part-words and phantom-word vs. part-word trials, performance was somewhat better when white shapes were presented on a black background. There were no other main effects or interactions with polarity type. 